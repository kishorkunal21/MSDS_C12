{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512b5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd8d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawnx(g):\n",
    "    gx = dgl.to_networkx(g)\n",
    "    nx.draw(gx, with_labels=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41424585",
   "metadata": {},
   "source": [
    "#### Implementing GAT in DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e0ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "    \n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e' : F.leaky_relu(a)}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z' : edges.src['z'], 'e' : edges.data['e']}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h' : h}\n",
    "    \n",
    "    def forward(self, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2933f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "    \n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9990d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "    \n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a823f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        #   multiple head outputs are concatenated together. Also, only\n",
    "        #   one attention head in the output layer.\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a6f7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dgl.data.citation_graph.CoraGraphDataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "data = citegrh.load_cora()\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "675613ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl\n",
    "coradata =  dgl.data.CoraGraphDataset()\n",
    "coradata.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1ff0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dgl.heterograph.DGLHeteroGraph"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(coradata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e41d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d4144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b366623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kunal21/opt/miniconda3/envs/gnnnlp2/lib/python3.10/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.feat will be deprecated, please use g.ndata['feat'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "/Users/kunal21/opt/miniconda3/envs/gnnnlp2/lib/python3.10/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.label will be deprecated, please use g.ndata['label'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
      "/Users/kunal21/opt/miniconda3/envs/gnnnlp2/lib/python3.10/site-packages/dgl/data/utils.py:288: UserWarning: Property dataset.train_mask will be deprecated, please use g.ndata['train_mask'] instead.\n",
      "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n"
     ]
    }
   ],
   "source": [
    "# from dgl import DGLGraph\n",
    "# from dgl.data import citation_graph as citegrh\n",
    "\n",
    "\n",
    "#data = citegrh.load_cora()\n",
    "features = torch.FloatTensor(coradata.features)\n",
    "labels = torch.LongTensor(coradata.labels)\n",
    "mask = torch.ByteTensor(coradata.train_mask)\n",
    "g = coradata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1853426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dgl import DGLGraph\n",
    "# from dgl.data import citation_graph as citegrh\n",
    "\n",
    "# def load_cora_data():\n",
    "#     data = citegrh.load_cora()\n",
    "#     features = torch.FloatTensor(data.features)\n",
    "#     labels = torch.LongTensor(data.labels)\n",
    "#     mask = torch.ByteTensor(data.train_mask)\n",
    "#     g = DGLGraph(data.load)\n",
    "#     return g, features, labels, mask\n",
    "def load_cora_data():\n",
    "    features = torch.FloatTensor(coradata.features)\n",
    "    labels = torch.LongTensor(coradata.labels)\n",
    "    mask = torch.ByteTensor(coradata.train_mask)\n",
    "    g = coradata[0]   \n",
    "    return g, features, labels, mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f59a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (layer1): MultiHeadGATLayer(\n",
      "    (heads): ModuleList(\n",
      "      (0): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (1): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (2): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (3): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (4): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (5): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (6): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "      (7): GATLayer(\n",
      "        (fc): Linear(in_features=1433, out_features=8, bias=False)\n",
      "        (attn_fc): Linear(in_features=16, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): MultiHeadGATLayer(\n",
      "    (heads): ModuleList(\n",
      "      (0): GATLayer(\n",
      "        (fc): Linear(in_features=64, out_features=7, bias=False)\n",
      "        (attn_fc): Linear(in_features=14, out_features=1, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Epoch 00000 | Loss 1.9458 | Time(s) nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_p/84b9pkm51s74vx6gr3q75qlm0000gn/T/ipykernel_48088/4128110125.py:24: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525498485/work/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  loss = F.nll_loss(logp[mask], labels[mask])\n",
      "/Users/kunal21/opt/miniconda3/envs/gnnnlp2/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525498485/work/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/Users/kunal21/opt/miniconda3/envs/gnnnlp2/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/kunal21/opt/miniconda3/envs/gnnnlp2/lib/python3.10/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001 | Loss 1.9443 | Time(s) nan\n",
      "Epoch 00002 | Loss 1.9428 | Time(s) nan\n",
      "Epoch 00003 | Loss 1.9413 | Time(s) 0.1589\n",
      "Epoch 00004 | Loss 1.9397 | Time(s) 0.1607\n",
      "Epoch 00005 | Loss 1.9382 | Time(s) 0.1589\n",
      "Epoch 00006 | Loss 1.9366 | Time(s) 0.1585\n",
      "Epoch 00007 | Loss 1.9349 | Time(s) 0.1587\n",
      "Epoch 00008 | Loss 1.9332 | Time(s) 0.1590\n",
      "Epoch 00009 | Loss 1.9315 | Time(s) 0.1593\n",
      "Epoch 00010 | Loss 1.9298 | Time(s) 0.1591\n",
      "Epoch 00011 | Loss 1.9279 | Time(s) 0.1593\n",
      "Epoch 00012 | Loss 1.9261 | Time(s) 0.1595\n",
      "Epoch 00013 | Loss 1.9242 | Time(s) 0.1595\n",
      "Epoch 00014 | Loss 1.9222 | Time(s) 0.1594\n",
      "Epoch 00015 | Loss 1.9202 | Time(s) 0.1592\n",
      "Epoch 00016 | Loss 1.9181 | Time(s) 0.1597\n",
      "Epoch 00017 | Loss 1.9160 | Time(s) 0.1597\n",
      "Epoch 00018 | Loss 1.9138 | Time(s) 0.1598\n",
      "Epoch 00019 | Loss 1.9116 | Time(s) 0.1601\n",
      "Epoch 00020 | Loss 1.9093 | Time(s) 0.1604\n",
      "Epoch 00021 | Loss 1.9070 | Time(s) 0.1608\n",
      "Epoch 00022 | Loss 1.9046 | Time(s) 0.1610\n",
      "Epoch 00023 | Loss 1.9021 | Time(s) 0.1609\n",
      "Epoch 00024 | Loss 1.8995 | Time(s) 0.1610\n",
      "Epoch 00025 | Loss 1.8969 | Time(s) 0.1613\n",
      "Epoch 00026 | Loss 1.8943 | Time(s) 0.1614\n",
      "Epoch 00027 | Loss 1.8915 | Time(s) 0.1618\n",
      "Epoch 00028 | Loss 1.8887 | Time(s) 0.1620\n",
      "Epoch 00029 | Loss 1.8859 | Time(s) 0.1619\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "g, features, labels, mask = load_cora_data()\n",
    "\n",
    "# create the model\n",
    "net = GAT(g, \n",
    "          in_dim=features.size()[1], \n",
    "          hidden_dim=8, \n",
    "          out_dim=7, \n",
    "          num_heads=8)\n",
    "print(net)\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# main loop\n",
    "dur = []\n",
    "for epoch in range(30):\n",
    "    if epoch >=3:\n",
    "        t0 = time.time()\n",
    "        \n",
    "    logits = net(features)\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[mask], labels[mask])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch >=3:\n",
    "        dur.append(time.time() - t0)\n",
    "    \n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch, loss.item(), np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1959a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnnlp2",
   "language": "python",
   "name": "gnnnlp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (default, Mar  3 2022, 03:54:28) [Clang 12.0.0 ]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
